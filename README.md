# DISCLAIMER
This content has been published in support of the claims made in the book [The Language of Deception: Weaponizing Next Generation AI](https://www.amazon.com/Language-Deception-Weaponizing-Next-Generation/dp/1394222548/), written by [Justin Hutchens](https://www.linkedin.com/in/justinhutchens/) and published by [Wiley](https://www.wiley.com/). **This content is intended exclusively for academic purposes.**

# Simulations
This repository contains a collection of Monte Carlo simulation proof-of-concepts (PoCs) for social engineering optimization. Monte Carlo simulations use random sampling to forecast the likelihood of different outcomes, and LLMs require no special tuning to make them useful for this purpose. This is because modern LLMs are already probabilistic models that use random sampling when generating output to create variability in their responses. Monte Carlo simulations can be executed by using an LLM service to play the roles of both the social engineering system and also the target victim. By crafting instructions for each, it is possible to tailor and optimize attacks towards specific types of targets. 

In the first Monte Carlo simulation (a series of 500 different tests were conducted using the code provided in simulations1.py), the social engineering system was successful in getting the target to disclose their password approximately 55% of the time (277 out of 500 tests). Transcripts of these conversations are included in this repo for reference (in the Model_Test1 directory). Based on the analysis from those results, the prompt used to create the social engineering agent was adjusted (see simulations2.py) and the simulation was run again. After updating the social engineering system, another Monte Carlo simulation was run (consisting of another series of 500 tests). In this subsequent series of tests, the system was successful in acquiring the target victim’s password 69% of the time (347 out of 500 tests) – an impressive 14% increase in effectiveness (results included in the Model_Test2 directory). 

In the final simulation, the agent instructions for the simulated target victim was updated to instruct it to remain mindful of its information assurance training (see simulations3.py). By performing a Monte Carlo simulation with this updated target agent, the number of successful social engineering attacks (where the social engineering agent was successful in persuading the target agent to disclose their password) dropped to 32% (161 out of 500 tests) – a total reduction of 37%. This test demonstrated that by refining the simulated target victim, it is also possible to evaluate the attack systems capabilities against more resilient targets (results included in the Model_Test2 directory).
